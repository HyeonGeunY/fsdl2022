{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab01_pytorch.ipynb","provenance":[],"mount_file_id":"1mcN0Rc23_84xQsdzQ3zexnk28iyKMdLG","authorship_tag":"ABX9TyP7N4eHXWXF3DQBfxWH7LWS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lab01: Deep Neural Networks in pytorch"],"metadata":{"id":"jbMId_9os7bz"}},{"cell_type":"markdown","source":["## 배울 내용"],"metadata":{"id":"1U9Ytui6tVPG"}},{"cell_type":"markdown","source":["- Pytorch를 이용한 간단한 neural network 작성방법\n","- torch, torch.nn, torch.utils.data와 같은 submodule이 학습과 추론 과정을 효율적으로 작성하게 해주는지"],"metadata":{"id":"6cOuYwsytblF"}},{"cell_type":"markdown","source":["핵심적으로 Pytorch 라이브러리는 아래의 역할을 수행해준다.    \n","- 행렬 계산\n","- 자동 미분\n","- GPU 가속과 여러 노드 분배"],"metadata":{"id":"XVKtzPNXtsSx"}},{"cell_type":"markdown","source":["대부분의 시간에 우리는 Pytorch의 핵심 기능을 제거하는 일을 해본다. ([What is `torch.nn` really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html). 참고)     \n","우리는 ML와 DNNs 구조에 대해 익숙하다는 것을 전제에 두기 때문에 refreshing을 위해서 아래의 영상을 참고하는 것을 추천한다.      \n","[3Blue1Brown's videos](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&ab_channel=3Blue1Brown)\n","or\n","[the NYU course on deep learning by Le Cun and Canziani](https://cds.nyu.edu/deep-learning/)"],"metadata":{"id":"Ypl3pFupt6Ub"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"1WZujfbSuxMs"}},{"cell_type":"markdown","source":["Google colab을 사용한다면 아래의 cell은 필요한 모든 환경을 설치해준다."],"metadata":{"id":"VkFkryo4uzAj"}},{"cell_type":"code","source":["lab_idx = 1\n","\n","if \"bootstrap\" not in locals() or bootstrap.run:\n","    # path management for Python\n","    pythonpath, = !echo $PYTHONPATH\n","    if \".\" not in pythonpath.split(\":\"):\n","        pythonpath = \".:\" + pythonpath\n","        %env PYTHONPATH={pythonpath}\n","        !echo $PYTHONPATH\n","\n","    # get both Colab and local notebooks into the same state\n","    !wget --quiet https://fsdl.me/gist-bootstrap -O bootstrap.py\n","    import bootstrap\n","\n","    # change into the lab directory\n","    bootstrap.change_to_lab_dir(lab_idx=lab_idx)\n","\n","    # allow \"hot-reloading\" of modules\n","    %load_ext autoreload\n","    %autoreload 2\n","\n","    bootstrap.run = False  # change to True re-run setup\n","    \n","!pwd\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SU1xnVcvu8UY","executionInfo":{"status":"ok","timestamp":1660192870326,"user_tz":-540,"elapsed":61905,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"5769028a-2c4b-41e6-94dc-50ee3a233805"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["env: PYTHONPATH=.:/env/python\n",".:/env/python\n","/content/fsdl-text-recognizer-2022-labs/lab01\n","\u001b[0m\u001b[01;34mnotebooks\u001b[0m/  \u001b[01;34mtext_recognizer\u001b[0m/\n"]}]},{"cell_type":"markdown","source":["# Getting data and making `Tensor`s"],"metadata":{"id":"rvyPJhSiu8lj"}},{"cell_type":"markdown","source":["모델을 만들기 전에 우리는 데이터가 필요하다.     \n","아래의 코드는 [MNIST dataset of handwritten digits](https://en.wikipedia.org/wiki/MNIST_database)를 다운받기위해 파이썬 표준 라이브러리를 사용한다.     \n","       \n","       \n","최근 state-of-art 모델에 사용되는 데이터는 일반적으로 매우 크기 때문에 단일 모델에 저장되지 않는다(RAM은 말할 것도 없이)      \n","따라서 네트워크를 통해 데이터를 가져오는 것은 모델을 훈련시키기 위해 일반적으로 수행하는 첫 번째 일이다."],"metadata":{"id":"c_BWAoQmvFDy"}},{"cell_type":"code","source":["from pathlib import Path\n","import requests\n","\n","\n","def download_mnist(path):\n","    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n","    filename = \"mnist.pkl.gz\"\n","\n","    if not (path / filename).exists():\n","        content = requests.get(url + filename).content\n","        (path / filename).open(\"wb\").write(content)\n","\n","    return path / filename\n","\n","\n","data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n","path = data_path / \"downloaded\" / \"vector-mnist\"\n","path.mkdir(parents=True, exist_ok=True)\n","\n","datafile = download_mnist(path)"],"metadata":{"id":"7w9YFBWowFxe","executionInfo":{"status":"ok","timestamp":1660192871352,"user_tz":-540,"elapsed":1031,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["더 큰 데이터는 더 많은 자원을 사용한다. -- 네트워크를 통해 데이터를 읽고 쓰고 보낼때 -- 따라서 데이터 셋은 압축되어 있다.(`.gz` 확장자)      \n","각 데이터셋 조각들(훈련과 검증데이터의 input과 output)은 단일 파이썬 객체이다.(array)     \n","우리는 `pickle` 라이브러리를 이용하여(`.pkl` 확장자) 파이썬 객체를 디스크에 저장할 수 있고(serialization) 다시 불러올 수 있다(deserialization)"],"metadata":{"id":"gYgdzXEMwk9i"}},{"cell_type":"code","source":["import gzip\n","import pickle\n","\n","\n","def read_mnist(path):\n","    with gzip.open(path, \"rb\") as f:\n","        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n","    return x_train, y_train, x_valid, y_valid\n","\n","x_train, y_train, x_valid, y_valid = read_mnist(datafile)"],"metadata":{"id":"TsnduccSxi3r","executionInfo":{"status":"ok","timestamp":1660192872329,"user_tz":-540,"elapsed":982,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["파이토치는 자체적으로 array를 표현하는 타입인 `torch.Tensor`를 가지고 있다. 아래의 cell은 array를 `torch.Tensor` 타입으로 바꿔준다.      \n","\"ML\" 에서의 \"tensor\"는 물리, 수학, 컴퓨터공학 등에서 이야기하는 tensor와 의미가 다르다.     \n","간단하게 말하면 \"ML\"에서의 tensor는 단지 2차원 이상의 array를 의미한다."],"metadata":{"id":"SV8ovv7yxoj2"}},{"cell_type":"code","source":["import torch\n","\n","\n","x_train, y_train, x_valid, y_valid = map(\n","    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",")"],"metadata":{"id":"aA6tKuygyZnl","executionInfo":{"status":"ok","timestamp":1660192875442,"user_tz":-540,"elapsed":3117,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["텐서들은 그들이 포함하고 있는 array의 내용에 따라 작성된다."],"metadata":{"id":"N-L7X1rDybFD"}},{"cell_type":"code","source":["print(x_train, y_train, sep=\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ73D6j7ykf5","executionInfo":{"status":"ok","timestamp":1660192875443,"user_tz":-540,"elapsed":10,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"dc634299-db6d-41d0-8359-02b1028b26bb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])\n","tensor([5, 0, 4,  ..., 8, 4, 8])\n"]}]},{"cell_type":"markdown","source":["텐서에 접근하는 것은 \"indexing\"이라고 불린다.    기본적인 파이썬 인덱싱 syntax와 같이, 이는 `항상 새로운 Tensor를 반환`한다."],"metadata":{"id":"XplkNGnxylAr"}},{"cell_type":"code","source":["y_train[0], x_train[0, ::2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GxkKoXFzAFp","executionInfo":{"status":"ok","timestamp":1660192875444,"user_tz":-540,"elapsed":9,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"5dbc9061-1053-4ca3-acd9-7636ed9ea85b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(5),\n"," tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0117, 0.0703, 0.4922, 0.6836, 0.6484,\n","         0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1172, 0.3672,\n","         0.6641, 0.9883, 0.9883, 0.8789, 0.9883, 0.7617, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.9297, 0.9883, 0.9883, 0.9883, 0.9883, 0.3633,\n","         0.3203, 0.1523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8555,\n","         0.9883, 0.9883, 0.7734, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.4180, 0.9883, 0.0430, 0.1680,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0039, 0.9883, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.0078,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.7422, 0.2734, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1367,\n","         0.8789, 0.4219, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9375, 0.9883, 0.0977, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.1758, 0.9883, 0.5859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3633, 0.9883,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.9883, 0.2500, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1797, 0.7148,\n","         0.9883, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.1523, 0.8945, 0.9883, 0.9766, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0938, 0.8633, 0.9883,\n","         0.9883, 0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0898, 0.8320, 0.9883, 0.9883, 0.3164, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0703, 0.8555, 0.9883, 0.9883,\n","         0.3125, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.2148, 0.8828, 0.9883, 0.9883, 0.5195, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5312, 0.9883, 0.8281, 0.5156,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["대부분의 array 연산을 수행하는 고성능 라이브러리와 마찬가지로 PyTorch는 Tensor에 대한 metadata를 제공하는 방법이 존재한다.      \n","가장 중요한 metadata 중 하나는 dimension과 shape 이다.      \n","dimension은 우리가 array에서 숫자를 얻기 위해 필요한 index의 수를 지정한다."],"metadata":{"id":"TCpLTebizBKR"}},{"cell_type":"code","source":["x_train.ndim, y_train.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fKhWG73zxol","executionInfo":{"status":"ok","timestamp":1660192875800,"user_tz":-540,"elapsed":361,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"660cf504-201a-4aea-eeb8-856bb20cbf5f"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 1)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["x_train[0, 0], y_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dp0CRBYxzyn4","executionInfo":{"status":"ok","timestamp":1660192875800,"user_tz":-540,"elapsed":7,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"b71c41ee-b81c-46be-d9e6-53b738a78d3e"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.), tensor(5))"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["`y_train`과 같은 1차원 텐서의 경우 shape는 얼마나 많은 항목을 가지고 있는지를 보여준다.     \n","`x_trian`과 같은 2차원 텐서에서 shape는 해당 텐서의 row와 column의 수를 나타내준다."],"metadata":{"id":"ryVmEKIjz975"}},{"cell_type":"code","source":["n, c = x_train.shape\n","print(x_train.shape)\n","print(y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwjeCkgqzzzD","executionInfo":{"status":"ok","timestamp":1660192875801,"user_tz":-540,"elapsed":5,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"fe7db9e5-6e6b-4c26-a82f-d10793853e77"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50000, 784])\n","torch.Size([50000])\n"]}]},{"cell_type":"markdown","source":["이 metadata는 파이썬의 다른 객체들의 metadata와 비슷한 역할을 수행한다.      \n","즉, 객체가 함수에 적절한 input과 output인지 정보를 알려주는 역할을 한다.     \n","대부분의 `Tensor`객체를 받는 함수들(indexing, 행렬 곱 등)은 특정 형태와 차원을 갖는 `Tensor`객체만을 받는다.     \n","따라서 계산 중간에 `ndim`과 `shape`를 사용하여 `Tensor`객체의 형태를 확인하는 것은 매우 중요한 디버깅 작업이다."],"metadata":{"id":"Yo-vrXALz9cw"}},{"cell_type":"markdown","source":["We won't spend much time here on writing raw array math code in PyTorch,\n","nor will we spend much time on how PyTorch works.\n","\n","> If you'd like to get better at writing PyTorch code,\n","try out\n","[these \"Tensor Puzzles\" by Sasha Rush](https://github.com/srush/Tensor-Puzzles).\n","We wrote a bit about what these puzzles reveal about programming\n","with arrays [here](https://twitter.com/charles_irl/status/1517991568266776577?s=20&t=i9cZJer0RPI2lzPIiCF_kQ).\n","\n","> If you'd like to get a better understanging of the internals\n","of PyTorch, check out\n","[this blog post by Edward Yang](http://blog.ezyang.com/2019/05/pytorch-internals/).\n","\n","As we'll see below,\n","`torch.nn` provides most of what we need\n","for building deep learning models."],"metadata":{"id":"flSWEhJpSQB2"}},{"cell_type":"markdown","source":["`x_train` 안에 담겨있는 텐서는 임의의 값이 아니라, 손으로 쓰여진 숫자 이미지에 대한 정보를 담고 있다.     \n","`y_train`은 각 숫자의 정답에 해당하는 텐서를 가지고 있다."],"metadata":{"id":"8sAo_ZdNSbBm"}},{"cell_type":"code","source":["import random\n","import wandb\n","import text_recognizer.metadata.mnist as metadata\n","\n","idx = random.randint(0, len(x_train))\n","example = x_train[idx]\n","\n","print(y_train[idx])\n","wandb.Image(example.reshape(*metadata.DIMS)).image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":64},"id":"HWI5loCzSzz1","executionInfo":{"status":"ok","timestamp":1660192878915,"user_tz":-540,"elapsed":3116,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"bc0fdcb2-0aa0-43dc-c831-121f49296661"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(9)\n"]},{"output_type":"execute_result","data":{"text/plain":["<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x7FDFFF1C3D50>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABj0lEQVR4nO3Sr6oCQRQG8LkrumJTQUVwTEb1BWwiNqNYZIMgGowGgybFtMUFwXcQNrkPIGxRNmiwWBf/wCImQcFvbxi4CBdU5k654NfmDOfHYeYQ8sknr9Lv913XBeC6rq7rmUzmr+JgMLjf73iIZVnhcJhfbLVaTNQ0TVGU4XC42WwAmKbJKQaDwel0CqDRaEiSxIrtdhvA6XQKhUI8qKqqALrdrsfjYZVkMrlerwEYhuH1enlQy7IApFIpdqSUGobBnnU0GvGI0Wh0sVgAoJRSSovFommaP39VKBR4UELI8XgEYNv2+Xx+/P39fi/LMidar9eXyyV+ZTKZPOn6eulGIpFqtRoIBLbbbalUqlQqt9stn8/zr9RjyuUyG3M2mwngCCGyLOu6DuB6veZyOTEoW3gA4/FYjOjz+djCOo6TTqfFoL1ej42pqqoYMZFIOI4DYLfbxeNxMaimaWzMTqcjRsxms5fLhb1mLBZ7s0t6fl2r1fx+PyFkPp8fDgcxqG3bhJDVatVsNt8U/1W+AeYwBMf6a0QIAAAAAElFTkSuQmCC\n"},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["이미지를 받고 해당하는 숫자를 결과로 출력하는 모델을 간단한 torch 모델부터 시작해서 실제 사용하는 모델로 발전시킨다."],"metadata":{"id":"nPNcf3zfTQcY"}},{"cell_type":"markdown","source":["# `torch.Tensor`와 python만 이용하여 DNN 구축하기"],"metadata":{"id":"std5Id_DU2Mu"}},{"cell_type":"markdown","source":["## Defining the model"],"metadata":{"id":"y-d7K5mhVFRk"}},{"cell_type":"markdown","source":["torch로 텐서를 만들기 위해서는 `값`과, `미분 값을 사용할지 여부(reguires_grad)`를 전달해야한다."],"metadata":{"id":"8azZdQcLVHfm"}},{"cell_type":"code","source":["import math\n","import torch\n","\n","weights = torch.randn(784, 10) / math.sqrt(784)\n","weights.requires_grad_()\n","bias = torch.zeros(10, requires_grad=True)"],"metadata":{"id":"0h3faY-DVeLF","executionInfo":{"status":"ok","timestamp":1660192878916,"user_tz":-540,"elapsed":39,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def linear(x: torch.Tensor) -> torch.Tensor:\n","    return x @ weights + bias"],"metadata":{"id":"ZcF607FhVpEl","executionInfo":{"status":"ok","timestamp":1660192878917,"user_tz":-540,"elapsed":39,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["모델의 output을 확률 값으로 바꾸기 위해 `softmax`를 이용한다.     \n","numerically stablity를 위해서 softmax에 logarithm을 계산한다. [it is more natural to work with the logarithms of probabilities](https://youtu.be/LBemXHm_Ops?t=1071)."],"metadata":{"id":"hv3BrRGMV2wm"}},{"cell_type":"markdown","source":["$log({exp(x_i) \\over {\\sum_j exp(x_j)}}) = x_i - log({{\\sum_j exp(x_j)}})$"],"metadata":{"id":"af2xu6n0WsH6"}},{"cell_type":"code","source":["def log_softmax(x: torch.Tensor) -> torch.Tensor:\n","    return x - torch.log(torch.sum(torch.exp(x), axis=1))[:, None] # None sum 으로 인해 없어지는 axis=1 차원 유지\n","\n","def model(xb: torch.Tensor) -> torch.Tensor:\n","    return log_softmax(linear(xb))"],"metadata":{"id":"l-VCmUfTWZ9r","executionInfo":{"status":"ok","timestamp":1660192878917,"user_tz":-540,"elapsed":39,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["일반적으로, 학습시 데이터를 작은 \"batch\" 단위로 나누게 된다."],"metadata":{"id":"XtO6n5UHXS8j"}},{"cell_type":"code","source":["bs = 64\n","xb = x_train[0:bs]\n","outs = model(xb)\n","\n","print(outs[0], outs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPP6UBxfXhkL","executionInfo":{"status":"ok","timestamp":1660192878917,"user_tz":-540,"elapsed":38,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"ae030142-e6de-4565-8406-cf82828a9f96"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-2.2369, -1.9443, -2.6531, -2.2017, -2.5600, -2.0436, -2.5377, -2.2186,\n","        -2.5019, -2.3808], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"]}]},{"cell_type":"code","source":["print(xb.shape)\n","print(torch.log(torch.sum(torch.exp(xb), axis=1))[:, None].shape)\n","print(torch.log(torch.sum(torch.exp(xb), axis=1))[:].shape)\n","print(x_train.shape)\n","print(x_train[:].shape)\n","print(x_train[:, :, None].shape)\n","print(x_train[:, None, :].shape)\n","print(x_train[:, None].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1JPvB0SrX_OM","executionInfo":{"status":"ok","timestamp":1660192878918,"user_tz":-540,"elapsed":35,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"4659e4b4-e702-4f2f-901e-f82654dcf2b0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 784])\n","torch.Size([64, 1])\n","torch.Size([64])\n","torch.Size([50000, 784])\n","torch.Size([50000, 784])\n","torch.Size([50000, 784, 1])\n","torch.Size([50000, 1, 784])\n","torch.Size([50000, 1, 784])\n"]}]},{"cell_type":"markdown","source":["## loss와 평가 지표(metrics) 정의"],"metadata":{"id":"1VVHlaUVYGH2"}},{"cell_type":"markdown","source":["모델의 결과를 정답 레이블와 일치기키기 위해 각 샘플당 가장 높은 확률을 갖는 클래스를 정답 레이블과 비교한다."],"metadata":{"id":"IZ_B3IDPYm93"}},{"cell_type":"code","source":["def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n","    preds = torch.argmax(out, dim=1)\n","    return (preds == yb).float().mean()"],"metadata":{"id":"8HKFuxi2ZQci","executionInfo":{"status":"ok","timestamp":1660192878918,"user_tz":-540,"elapsed":33,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["yb = y_train[0:bs]\n","\n","acc = accuracy(outs, yb)\n","\n","print(acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KjFpvzo7ZXW2","executionInfo":{"status":"ok","timestamp":1660192878918,"user_tz":-540,"elapsed":32,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"df05d383-30ed-4e58-de9f-e8f554fd2ee7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.0312)\n"]}]},{"cell_type":"markdown","source":["모델이 random하게 초기화되어 있기 때문에 성능이 좋지 못하다."],"metadata":{"id":"9fl-ZBheafSg"}},{"cell_type":"markdown","source":["acc 자체는 backward 계산을 못하기 때문에 모델을 학습시키는데 사용할 수 없다."],"metadata":{"id":"hunQzwbhbS5c"}},{"cell_type":"code","source":["try:\n","    acc.backward()\n","except RuntimeError as e:\n","    print(e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcmhLH0UamOk","executionInfo":{"status":"ok","timestamp":1660192878919,"user_tz":-540,"elapsed":31,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"8d5dbf1c-8a3f-41e5-c52f-2691f0f1057c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["element 0 of tensors does not require grad and does not have a grad_fn\n"]}]},{"cell_type":"markdown","source":["분류 문제에 주로 사용되는 cross entropy loss르 사용한다."],"metadata":{"id":"_5SLHtkkbW-5"}},{"cell_type":"code","source":["def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n","    return -output[range(target.shape[0]), target].mean()\n","\n","loss_func = cross_entropy"],"metadata":{"id":"G4B29cIma6nf","executionInfo":{"status":"ok","timestamp":1660192878919,"user_tz":-540,"elapsed":29,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(loss_func(outs, yb), -torch.log(torch.tensor(1 / 10)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgsHqJzhbRqB","executionInfo":{"status":"ok","timestamp":1660192878919,"user_tz":-540,"elapsed":28,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"3409ed94-73e9-4c3f-f70b-3ca32e9d9d2e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.4536, grad_fn=<NegBackward0>) tensor(2.3026)\n"]}]},{"cell_type":"markdown","source":["uniform random digit으로 초기화 했으므로 정답 확률 갑슨 1/10에 수렵할 것을 예측할 수 있다."],"metadata":{"id":"gCGEYW0qbluT"}},{"cell_type":"markdown","source":["`.backward`를 이용하여 미분을 계산한다.\n"],"metadata":{"id":"2Dj2gnm2cY4x"}},{"cell_type":"code","source":["loss = loss_func(outs, yb)\n","\n","loss.backward()"],"metadata":{"id":"dtyBGGZ_cXIS","executionInfo":{"status":"ok","timestamp":1660192878920,"user_tz":-540,"elapsed":27,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["`.backward`를 수행하게 되면 `requires_grad=True`인 `tensor`객체의 `.grad`에 미분 값이 저장된다."],"metadata":{"id":"r4mlFcWscjZ4"}},{"cell_type":"code","source":["bias.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDyaoBXlcbjm","executionInfo":{"status":"ok","timestamp":1660192878920,"user_tz":-540,"elapsed":27,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"844b218a-1c22-491b-c3b0-efbc40c5f3b1"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.0168, -0.0140,  0.0242, -0.0543, -0.0163,  0.0904, -0.0030,  0.0456,\n","        -0.0026, -0.0533])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## 훈련 루프 작성 및 실행"],"metadata":{"id":"04ZW5py0chpC"}},{"cell_type":"markdown","source":["네트워크를 학습시키기 위한 필요사항들을 모두 준비했다.     \n","- data\n","- parameter(model, weight, bias)를 가지고 있는 architecture\n","- loss_function     \n","이제 `for` loop, indexing, 함수 호출을 이용하여 학습을 진행할 수 있다."],"metadata":{"id":"kPjFJxcsetgT"}},{"cell_type":"code","source":["lr = 0.5 \n","epochs = 2\n","\n","for epoch in range(epochs):\n","    for ii in range((n - 1) // bs + 1):\n","        start_idx = ii * bs\n","        end_idx = start_idx + bs\n","        xb = x_train[start_idx:end_idx]\n","        yb = y_train[start_idx:end_idx]\n","        # print(yb.shape)\n","        pred = model(xb)\n","        loss = loss_func(pred, yb)\n","\n","        loss.backward()\n","        \n","        with torch.no_grad(): # 이 계산 동안은 gradient를 추적하지 않는다.\n","            weights -= weights.grad * lr\n","            bias -= bias.grad * lr\n","\n","            weights.grad.zero_()\n","            bias.grad.zero_()\n"],"metadata":{"id":"JCygWw6YeqJ_","executionInfo":{"status":"ok","timestamp":1660192878920,"user_tz":-540,"elapsed":25,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["print(loss_func(model(xb), yb), accuracy(model(xb), yb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGM_R0U4gFzw","executionInfo":{"status":"ok","timestamp":1660192878920,"user_tz":-540,"elapsed":24,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"ca3377b7-8e42-4bd1-e9a3-0b9f0187b8f1"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.0802, grad_fn=<NegBackward0>) tensor(1.)\n"]}]},{"cell_type":"code","source":["# re-execute this cell for more samples\n","idx = random.randint(0, len(x_train))\n","example = x_train[idx:idx+1]\n","\n","out = model(example)\n","\n","print(out.argmax())\n","wandb.Image(example.reshape(28, 28)).image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":64},"id":"81WH9GyrgLTh","executionInfo":{"status":"ok","timestamp":1660192878921,"user_tz":-540,"elapsed":23,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"b516def2-1720-4a82-8baf-f3cb790d70f4"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(8)\n"]},{"output_type":"execute_result","data":{"text/plain":["<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28 at 0x7FDFFF18C0D0>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABa0lEQVR4nO2TIasCQRSFz+qsi2WrmkQwrFW0arUoGNxkNFgMBtFiEvRHmA02EawigkXEH2CcssUgaFHw+MKEJy88fcyEF/zagTvfHLgzwIe3yefzk8lESlkoFMwYE4lEEAQkF4tFqVQyYLRte7VakRyPx0IIA0YAvu+TvFwusVjMjFEIsd/vSfq+b8YIoF6vkyTped4786F3hlKpFIDlcnk4HLTaPTOfz0mWy+U35183tSwrGo0CaLfb6XRaq933taGQ2pLa/mg0CofDulLbtkkGQeB5XqPRuF6vnU7HsiwDUimliq1Wi2Q2m9WSVqtVkrPZTEUhxOl0Gg6Hvxx5vSj1njabjYrFYtF13WQyqSXN5XIAdrudirVaDcDtdtOSPuM4TqVSAdDr9YxJ+/1+PB4/n8/H49GMNJPJNJtNAIPB4H6//6nNT7rdLsntdiulJLlerx3H0TICiEQi6kc9Ho/pdOq6rq7xw3/hC8kNmclQNwG3AAAAAElFTkSuQmCC\n"},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["# torch.nn을 이용한 리펙토링"],"metadata":{"id":"6uX_9ptuggWJ"}},{"cell_type":"markdown","source":["학습까지의 과정이 작동은 하지만 매우 번거롭다.      \n","`torch.nn`, `torch.optim`, `torch.utils.data`."],"metadata":{"id":"gApYyvMyYrqv"}},{"cell_type":"markdown","source":["# Using `torch.nn.functional` for stateless computation"],"metadata":{"id":"dQAYsNJuZMS2"}},{"cell_type":"markdown","source":["torch를 이용하여 기본적인 수식을 작성하기 전에 항상 해당 기능을 제공하는 함수라 pytorch 라이브러리에 있는지부터 확인하라"],"metadata":{"id":"ox5_-_rmZZTm"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","loss_func = F.cross_entropy\n","\n","def model(xb):\n","    return xb @ weights + bias"],"metadata":{"id":"OV5EPOWoZtxJ","executionInfo":{"status":"ok","timestamp":1660192878921,"user_tz":-540,"elapsed":21,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(loss_func(model(xb), yb), accuracy(model(xb), yb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OlQOfcbnZ6KJ","executionInfo":{"status":"ok","timestamp":1660192878921,"user_tz":-540,"elapsed":20,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"eb852c82-f281-4b0a-e603-473e7bee902a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.0802, grad_fn=<NllLossBackward0>) tensor(1.)\n"]}]},{"cell_type":"markdown","source":["# `torch.nn.Parameter`를 통해 상태(state)가 존재하는 함수를 정의하기 위해서는 `torch.nn`을 사용한다."],"metadata":{"id":"WEBXs0mNaA_J"}},{"cell_type":"markdown","source":["neural network는 최적화 과정을 거쳐야하므로 내부에 state가 존재한다(weight, bias). 우리가 추적하기를 원하는 모든 텐서들은 nn.Parameter로 정의되고 이는 model의 attribute에 저장되어 있다."],"metadata":{"id":"JsaeivWQaweJ"}},{"cell_type":"code","source":["from torch import nn\n","\n","class MNISTLogistic(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n","        self.bias = nn.Parameter(torch.zeros(10))"],"metadata":{"id":"zUgm6HR_aQwW","executionInfo":{"status":"ok","timestamp":1660192878921,"user_tz":-540,"elapsed":18,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["`.forward` 를 사용하면 파이썬의 `__call__` 매서드와 같이 nn.Module를 상속한 객체를 함수처럼 호출하였을 때 작동할 결과를 정의할 수 있다.     \n","`.forward`에는 `nn.Parameter`를 이용하여 정의한 state들을 이용하여 수행하는 연산을 정의한다."],"metadata":{"id":"tXGwGUoOcdGZ"}},{"cell_type":"code","source":["def forward(self, xb: torch.Tensor) -> torch.Tensor:\n","    return xb @ self.weights + self.bias\n","\n","MNISTLogistic.forward = forward\n","\n","model = MNISTLogistic()\n","print(model(xb)[:4])\n","loss = loss_func(model(xb), yb)\n","loss.backward()\n","print(model.weights.grad[::17, ::2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LJr9JiFbhWz","executionInfo":{"status":"ok","timestamp":1660192878922,"user_tz":-540,"elapsed":18,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"dedde627-a2df-4ebd-948a-80e65a547246"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.2465, -0.8651, -0.2091, -0.2762, -0.1541,  0.5474,  0.0163,  0.1913,\n","         -0.0381,  0.5062],\n","        [ 0.0402, -0.6032, -0.0817, -0.1863, -0.1107,  0.6191,  0.9044,  0.2905,\n","          0.3296,  0.1488],\n","        [ 0.0451, -0.5915, -0.4251, -0.2839, -0.0162,  0.4792,  0.3028,  0.2725,\n","         -0.3696, -0.1772],\n","        [ 0.3880, -0.6863, -0.2375, -0.3959,  0.1112,  0.5058,  0.3352,  0.5348,\n","         -0.1852,  0.4321]], grad_fn=<SliceBackward0>)\n","tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 6.3487e-03,  6.7917e-03,  6.5589e-03,  2.1063e-02,  7.6527e-03],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-3.2941e-02, -1.9713e-02,  4.3414e-02,  8.5573e-02, -1.4069e-01],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-2.7132e-02,  1.3425e-02, -3.9439e-02,  1.8068e-02, -4.4414e-02],\n","        [ 1.8512e-02,  1.9718e-02,  1.9680e-02,  4.6752e-02, -5.1255e-02],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-6.6734e-02,  1.2199e-02,  3.9179e-02,  5.7450e-02, -3.1672e-02],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-8.9735e-02,  1.8238e-02,  4.6711e-03,  2.8717e-02, -1.9148e-02],\n","        [-5.6484e-02,  4.8439e-02,  5.0204e-02,  8.6403e-02, -1.1971e-01],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 2.1211e-02,  2.2095e-02,  2.1000e-02,  5.7815e-02, -4.6069e-02],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-5.4191e-02,  6.3454e-03,  5.7143e-03,  7.1394e-03,  5.1638e-03],\n","        [ 2.3638e-02,  1.7225e-02, -5.7052e-02,  2.3877e-02, -4.4585e-02],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 4.4644e-02,  3.7094e-02, -2.0371e-02,  5.5568e-02, -8.1600e-02],\n","        [ 7.7745e-03,  4.2198e-03, -5.4630e-02,  4.5222e-03,  5.1269e-03],\n","        [-2.6772e-02,  3.9608e-03,  3.3122e-03,  4.3840e-03,  3.2351e-03],\n","        [-1.2528e-02, -2.2597e-02, -5.7002e-02,  5.6099e-02, -5.3953e-03],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-1.5946e-02, -1.9222e-02, -4.8025e-02,  6.5109e-02, -9.5104e-02],\n","        [-5.0992e-02,  5.5805e-03,  7.7706e-03,  1.2997e-02,  8.1749e-03],\n","        [-1.2387e-03,  9.4726e-05,  1.4762e-04,  1.9173e-04,  1.5435e-04],\n","        [-5.0905e-02,  3.2981e-02, -6.9474e-03,  6.3455e-02, -1.1686e-01],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-8.3423e-02,  2.6311e-02, -1.2145e-02,  8.3871e-02, -7.1412e-02],\n","        [-5.1090e-02,  5.5282e-03,  7.7133e-03,  1.2973e-02,  8.1096e-03],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-1.0130e-01,  4.3672e-03,  7.0752e-02,  1.2473e-01, -1.1453e-01],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 1.5427e-02,  1.3159e-02,  1.3788e-02,  2.4372e-02, -4.7034e-02],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 8.9249e-04,  6.6825e-04,  8.8684e-04,  1.1714e-03,  6.0442e-04],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"]}]},{"cell_type":"markdown","source":["`.Parameters` 매서드를 이용하면 우리 모델에 존재하는 모든 `torch.nn.Parameters`에 접근할 수 있다."],"metadata":{"id":"je3Jw9VZcSOQ"}},{"cell_type":"code","source":["print(*list(model.parameters()), sep=\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4X7KO1JneVfx","executionInfo":{"status":"ok","timestamp":1660192878922,"user_tz":-540,"elapsed":16,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"9c07b9d8-ecf3-45bf-cbd7-d0b64fd15c3c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[ 0.0263,  0.0418, -0.0333,  ..., -0.0458, -0.0098,  0.0689],\n","        [ 0.0106, -0.0493,  0.0020,  ...,  0.0403,  0.0024, -0.0343],\n","        [-0.0546, -0.0131, -0.0484,  ...,  0.0060, -0.0103,  0.0097],\n","        ...,\n","        [ 0.0462, -0.0803,  0.0055,  ..., -0.0489,  0.0187, -0.0293],\n","        [ 0.0174,  0.0316,  0.0307,  ..., -0.0371,  0.0313, -0.0229],\n","        [-0.0496, -0.0374,  0.0703,  ...,  0.0433,  0.0019, -0.0422]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["즉 사용자는 더 이상 model 파라미터의 이름을 알고 있을 필요가 없다.     \n","따라서 아래와 같이 다른 모델에 대해 같은 train loop를 작성할 수 있다."],"metadata":{"id":"JXBa-qHkeXY5"}},{"cell_type":"code","source":["def fit():\n","    for epoch in range(epochs):\n","        for ii in range((n - 1) // bs + 1):\n","            start_idx = ii * bs\n","            end_idx = start_idx + bs\n","            xb = x_train[start_idx: end_idx]\n","            yb = y_train[start_idx: end_idx]\n","            pred = model(xb)\n","            loss = loss_func(pred, yb)\n","\n","            loss.backward()\n","            with torch.no_grad():\n","                for p in model.parameters():\n","                    p -= p.grad * lr\n","                model.zero_grad()\n","fit()"],"metadata":{"id":"iu2ypDjGek56","executionInfo":{"status":"ok","timestamp":1660192879429,"user_tz":-540,"elapsed":520,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["print(accuracy(model(xb), yb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3YPS9bEhSfK","executionInfo":{"status":"ok","timestamp":1660192879429,"user_tz":-540,"elapsed":7,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"25803706-d297-4b69-cf7a-9f30f637dfe1"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.)\n"]}]},{"cell_type":"markdown","source":["# Refactoring intermediate `torch.nn` components: network layers, optimizers, data handling"],"metadata":{"id":"BtBsaSHChUy9"}},{"cell_type":"markdown","source":["## Using torch.nn.Linear for the model definition"],"metadata":{"id":"OMIqZ7xlqRX6"}},{"cell_type":"markdown","source":["`nn.Module`을 상속하여 custom layer를 만드는 것보다 사전에 정의된 layer를 사용할 수 있다."],"metadata":{"id":"iIrTrceYq6Pd"}},{"cell_type":"code","source":["import textwrap\n","\n","print(\"torch.nn.Modules:\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fM45hjD1qiaB","executionInfo":{"status":"ok","timestamp":1660192879429,"user_tz":-540,"elapsed":5,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"1498c84a-da1c-426e-e928-6a81d9270bf7"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.nn.Modules:\n","\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n","\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n","\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n","\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n","\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n","\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n","\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n","\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n","\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n","\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n","\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n","\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n","\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n","\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n","\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n","\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n","\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n","\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n","\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n","\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n","\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n","\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n","\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n","\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad2d,\n","\tConstantPad1d, ConstantPad2d, ConstantPad3d, Bilinear,\n","\tCosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n","\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n","\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n","\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n","\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n","\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n","\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n","\tMish, TripletMarginWithDistanceLoss, ChannelShuffle\n"]}]},{"cell_type":"code","source":["class MNISTLogistic(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.lin = nn.Linear(784, 10)\n","    \n","    def forward(self, xb):\n","        return self.lin(xb)"],"metadata":{"id":"Boceol8-rC6b","executionInfo":{"status":"ok","timestamp":1660192879763,"user_tz":-540,"elapsed":336,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["model = MNISTLogistic()\n","print(loss_func(model(xb), yb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJl2TLHBrRGJ","executionInfo":{"status":"ok","timestamp":1660192879763,"user_tz":-540,"elapsed":6,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"de83def7-8eb0-4f40-d7b0-0fc21f45169d"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.3718, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["`nn.Linear`을 `model`의 child로 볼 수 있다."],"metadata":{"id":"Yv5spqLZrbHi"}},{"cell_type":"code","source":["print(*list(model.parameters()), sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UdIbUu8roen","executionInfo":{"status":"ok","timestamp":1660192879764,"user_tz":-540,"elapsed":5,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"d7d48260-14c0-4b1d-acd3-ec908f50c9cd"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[-0.0299,  0.0109, -0.0134,  ...,  0.0154, -0.0264, -0.0009],\n","        [-0.0298,  0.0096, -0.0137,  ..., -0.0286, -0.0159,  0.0080],\n","        [-0.0097, -0.0036,  0.0186,  ..., -0.0036, -0.0074, -0.0109],\n","        ...,\n","        [ 0.0347, -0.0123, -0.0231,  ..., -0.0274, -0.0202,  0.0233],\n","        [ 0.0308, -0.0211, -0.0285,  ...,  0.0121, -0.0039,  0.0341],\n","        [-0.0223,  0.0314,  0.0147,  ...,  0.0260,  0.0226, -0.0201]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.0202, -0.0227,  0.0329, -0.0169,  0.0061,  0.0007,  0.0225, -0.0029,\n","         0.0167, -0.0034], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["# Applying gradients with `torch.optim.Optimizer`"],"metadata":{"id":"-fx8pShprrte"}},{"cell_type":"markdown","source":["## `torch.optim.Optimizer` 에 모델의 parameter들을 가르켜주면 최적화 과정을 손쉽게 해결할 수 있다."],"metadata":{"id":"wZucTCOhrz_x"}},{"cell_type":"code","source":["from torch import optim\n","\n","def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n","    return optim.Adam(model.parameters(), lr=3e-4)"],"metadata":{"id":"e-7NISQZs2fe","executionInfo":{"status":"ok","timestamp":1660192879764,"user_tz":-540,"elapsed":3,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["model = MNISTLogistic()\n","opt = configure_optimizer(model)\n","\n","print(\"before training:\", loss_func(model(xb), yb), sep='\\n\\t')\n","\n","for epoch in range(epochs):\n","    for ii in range((n - 1) // bs + 1):\n","        start_idx = ii * bs\n","        end_idx = start_idx + bs\n","        xb = x_train[start_idx: end_idx]\n","        yb = y_train[start_idx: end_idx]\n","        pred = model(xb)\n","        loss = loss_func(pred, yb)\n","        opt.step()\n","        opt.zero_grad()\n","\n","print(\"after training\", loss_func(model(xb), yb), sep='\\n\\t')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abxqmelBtA0U","executionInfo":{"status":"ok","timestamp":1660192880485,"user_tz":-540,"elapsed":723,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"ced1a974-8ca2-42ea-df39-c9aae30a6346"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["before training:\n","\ttensor(2.2517, grad_fn=<NllLossBackward0>)\n","after training\n","\ttensor(2.2517, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["## organizing data with `torch.utils.data.Dataset`"],"metadata":{"id":"F0uGP-ESt8nH"}},{"cell_type":"markdown","source":["`torch.utils.data.Dataset`을 이용하여 multiple data source에서 데이터 세트를 구성하고 indexing 할 수 있다.     \n","또한 input과 output의 transform을 효율적으로 수행할 수 있다."],"metadata":{"id":"1VLwze15wz13"}},{"cell_type":"code","source":["from text_recognizer.data.util import BaseDataset\n","\n","train_ds = BaseDataset(x_train, y_train)"],"metadata":{"id":"zV9rhn3RxK33","executionInfo":{"status":"ok","timestamp":1660192880485,"user_tz":-540,"elapsed":2,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["BaseDataset??"],"metadata":{"id":"DlH88XOOxRu8","executionInfo":{"status":"ok","timestamp":1660192880791,"user_tz":-540,"elapsed":308,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["model = MNISTLogistic()\n","opt = configure_optimizer(model)\n","\n","\n","for epoch in range(epochs):\n","    for ii in range((n - 1) // bs + 1):\n","        xb, yb = train_ds[ii * bs: ii * bs + bs]  # xb and yb in one line!\n","        pred = model(xb)\n","        loss = loss_func(pred, yb)\n","\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","\n","print(loss_func(model(xb), yb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mc6WuIcgxdUO","executionInfo":{"status":"ok","timestamp":1660192882820,"user_tz":-540,"elapsed":2031,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"98413af1-ab80-4c01-88f5-b6fa681bac06"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.8349, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["## Batching up data with `torch.utils.data.DataLoader`"],"metadata":{"id":"U2dBDt6QzFk1"}},{"cell_type":"markdown","source":["`DataLoader`를 이용하면 batch를 손쉽게 나눌 수 있다.     \n","`DataLoader`의 다른 옵션(num_workers, pin_memory)을 사용하면 training loop의 성능을 끌어올릴 수 있다."],"metadata":{"id":"3ypeOWQ9zm4t"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_ds = BaseDataset(x_train, y_train)\n","train_dataloader = DataLoader(train_ds, batch_size=bs)"],"metadata":{"id":"1hOF-kY6zLy2","executionInfo":{"status":"ok","timestamp":1660192882821,"user_tz":-540,"elapsed":4,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def fit(self: nn.Module, train_dataloader: DataLoader):\n","    opt = configure_optimizer(self)\n","\n","    for epoch in range(epochs):\n","        for xb, yb in train_dataloader:\n","            pred = self(xb)\n","            loss = loss_func(pred, yb)\n","\n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","\n","MNISTLogistic.fit = fit"],"metadata":{"id":"eViaJrvsz13x","executionInfo":{"status":"ok","timestamp":1660192882821,"user_tz":-540,"elapsed":3,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["model = MNISTLogistic()\n","\n","model.fit(train_dataloader)\n","\n","print(loss_func(model(xb), yb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xe1HuwZX0oaO","executionInfo":{"status":"ok","timestamp":1660192886656,"user_tz":-540,"elapsed":3838,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"48c40578-8054-4fc9-c1eb-d32f70440051"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.8498, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["아래의 이전 코드와 비교하면 매우 깔끔해진 것을 확인할 수 있다."],"metadata":{"id":"DeLGeIio2HP2"}},{"cell_type":"markdown","source":["```python\n","lr = 0.5  # learning rate\n","epochs = 2  # how many epochs to train for\n","\n","for epoch in range(epochs):\n","    for ii in range((n - 1) // bs + 1):\n","        start_idx = ii * bs\n","        end_idx = start_idx + bs\n","        xb = x_train[start_idx:end_idx]\n","        yb = y_train[start_idx:end_idx]\n","        pred = model(xb)\n","        loss = loss_func(pred, yb)\n","\n","        loss.backward()\n","        with torch.no_grad():\n","            weights -= weights.grad * lr\n","            bias -= bias.grad * lr\n","            weights.grad.zero_()\n","            bias.grad.zero_()\n","```"],"metadata":{"id":"2W6ndnLv2Lfy"}},{"cell_type":"markdown","source":["## Swapping in another model"],"metadata":{"id":"Du_WkKuy2NOc"}},{"cell_type":"markdown","source":["`.fit`의 성능을 체감하기 위해 다른 모델로 전환해본다."],"metadata":{"id":"gMYWPu0q2RME"}},{"cell_type":"code","source":["from text_recognizer.models.mlp import MLP\n","\n","MLP.fit = fit"],"metadata":{"id":"LtggIAGK2WBb","executionInfo":{"status":"ok","timestamp":1660192886656,"user_tz":-540,"elapsed":13,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["`MLP`의 `.forward` 매서드를 확인하면 [`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n","와 [`F.relu`](https://pytorch.org/docs/stable/generated/torch.nn.functional.relu.html) 같이 본 적이 없는 모듈과 함수가 포함되어 있는 것을 확인할 수 있으나 그 외에는 기존에 작성한 training loop와 잘 맞는 것을 확인할 수 있다.(`MLP`는 호출 가능하며, `X`를 input으로 받고 `y`를 예측한다.)"],"metadata":{"id":"gz2K1bez2n4F"}},{"cell_type":"code","source":["MLP.forward??"],"metadata":{"id":"Kt1_DrtV2ZDv","executionInfo":{"status":"ok","timestamp":1660192886657,"user_tz":-540,"elapsed":13,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["__init__을 살펴보면, nn.Module이 초기화되는 것을 확인할 수 있다."],"metadata":{"id":"WYlfyrxU3JT_"}},{"cell_type":"code","source":["MLP.__init__??"],"metadata":{"id":"gw2wvYWj3B1z","executionInfo":{"status":"ok","timestamp":1660192886669,"user_tz":-540,"elapsed":24,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["또한 MLP 모듈이 `data_config`를 요구하는 것을 확인할 수 있고, 선택적으로 `args`를 받는 것을 확인할 수 있다.      \n","지금은 최소한의 조건만 추가한다."],"metadata":{"id":"eM2Yh4Ni3Drq"}},{"cell_type":"code","source":["digits_to_9 = list(range(10))\n","data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n","data_config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXyRthy239oz","executionInfo":{"status":"ok","timestamp":1660192887148,"user_tz":-540,"elapsed":502,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"dcd8f68c-7d84-4818-99c9-5df5cd71c28d"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_dims': (784,),\n"," 'mapping': {0: '0',\n","  1: '1',\n","  2: '2',\n","  3: '3',\n","  4: '4',\n","  5: '5',\n","  6: '6',\n","  7: '7',\n","  8: '8',\n","  9: '9'}}"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["model = MLP(data_config)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bca1BNdK4KAj","executionInfo":{"status":"ok","timestamp":1660192887148,"user_tz":-540,"elapsed":11,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"ddf2ae67-e215-4e39-8a67-9673dba6de51"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLP(\n","  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["완성된 `MLP`는 우리의 `MNISTLogistic` 모델보다 조금 큰 것을 확인할 수 있다."],"metadata":{"id":"Zl6x5CUz4YFl"}},{"cell_type":"code","source":["model.fc1.weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8izkWRKV4iI1","executionInfo":{"status":"ok","timestamp":1660192887149,"user_tz":-540,"elapsed":8,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"2e086795-9250-46c0-e921-fb1978a64dec"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[ 0.0236,  0.0339, -0.0172,  ..., -0.0095,  0.0094, -0.0049],\n","        [-0.0068,  0.0085, -0.0114,  ..., -0.0100,  0.0260,  0.0141],\n","        [-0.0156, -0.0219,  0.0002,  ...,  0.0009,  0.0012,  0.0303],\n","        ...,\n","        [-0.0021, -0.0180,  0.0218,  ..., -0.0039, -0.0003, -0.0201],\n","        [ 0.0145,  0.0257,  0.0151,  ..., -0.0206,  0.0332,  0.0131],\n","        [-0.0131,  0.0047,  0.0017,  ...,  0.0253, -0.0139,  0.0013]],\n","       requires_grad=True)"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["하지만 시간이 좀 더 오래걸릴 뿐 훈련단계의 변화는 없다."],"metadata":{"id":"kTV3BP-m4jVo"}},{"cell_type":"code","source":["%%time\n","\n","print(\"before training\", loss_func(model(xb), yb))\n","\n","train_ds = BaseDataset(x_train, y_train)\n","train_dataloader = DataLoader(train_ds, batch_size=bs)\n","fit(model, train_dataloader)\n","\n","print(\"after training\", loss_func(model(xb), yb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jentEgz54qY-","executionInfo":{"status":"ok","timestamp":1660192915368,"user_tz":-540,"elapsed":28224,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"46ef54ab-7e9b-4e88-b82e-ab993dc13df5"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["before training tensor(2.2893, grad_fn=<NllLossBackward0>)\n","after training tensor(0.1888, grad_fn=<NllLossBackward0>)\n","CPU times: user 27.5 s, sys: 350 ms, total: 27.9 s\n","Wall time: 28.4 s\n"]}]},{"cell_type":"markdown","source":["# Extra goodies: data organization, validation, acceleration"],"metadata":{"id":"kKNkCVdv49TK"}},{"cell_type":"markdown","source":["CPU는 단일 연산에 특화되어 있기 때문에 DNN과 같은 병렬 행렬 연산이 필요한 작업에는 GPU를 사용하는 것이 작업을 훤씬 빠르게 끝낼 수 있다."],"metadata":{"id":"oLaqhb-p56G3"}},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    !nvidia-smi\n","else:\n","    print(\"☹️\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bL6eWF4O5V_S","executionInfo":{"status":"ok","timestamp":1660192915369,"user_tz":-540,"elapsed":7,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"0cdbfc13-9780-40f0-af8a-6cf95ee96e2d"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["☹️\n"]}]},{"cell_type":"markdown","source":["Pytorch는 CPU와 GPU를 모두 사용할 수 있고, 동시에도 사용가능하다. 따라서 `Tensor`가 CPU와 GPU 어디에 할당되어 있는지 설정해줄 필요가 있다.    \n","사용가능한 기기는 `torch.device`를 이용하여 확인할 수 있다.     \n","아래의 명령어는 모델의 파라미터를들 GPU로 이동시켜준다.(`.to`) 이는 `torch.nn.Parameter`를 사용하는 또다른 이점이다.      "],"metadata":{"id":"5m0nOhpG55nk"}},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","model.to(device)\n","\n","loss_func(model(xb.to(device)), yb.to(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tghpJcD-7YSO","executionInfo":{"status":"ok","timestamp":1660192915891,"user_tz":-540,"elapsed":525,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"e383492f-db19-4d91-ec27-21fbb10a90d5"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.2234, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["BaseDataset의 또다른 기능으로, input에 사용할 변환을 `transform` 인자에, 정답 레이블에 적용할 변환을 `target_transform`에 대입할 수 있다.\n"],"metadata":{"id":"iOM8MUJW7-YH"}},{"cell_type":"code","source":["def push_to_device(tensor):\n","    return tensor.to(device)\n","\n","train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n","train_dataloader = DataLoader(train_ds, batch_size=bs)"],"metadata":{"id":"sg6biP-T7lpj","executionInfo":{"status":"ok","timestamp":1660192915891,"user_tz":-540,"elapsed":2,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["별도로 training code를 바꿔주어야 하는 것은 없다."],"metadata":{"id":"i4pEbTAUMA8V"}},{"cell_type":"code","source":["%%time\n","\n","model = MLP(data_config)\n","model.to(device)\n","\n","model.fit(train_dataloader)\n","print(loss_func(model(push_to_device(xb)), push_to_device(yb)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oj_Sh48p8XTu","executionInfo":{"status":"ok","timestamp":1660192944775,"user_tz":-540,"elapsed":28885,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"255b748c-a079-42ae-8c6c-6e9f10f90079"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.3628, grad_fn=<NllLossBackward0>)\n","CPU times: user 27.5 s, sys: 537 ms, total: 28 s\n","Wall time: 29 s\n"]}]},{"cell_type":"markdown","source":["Writing high performance GPU-accelerated neural network code is challenging.\n","There are many sharp edges, so the default\n","strategy is imitation (basing all work on existing verified quality code)\n","and conservatism bordering on paranoia about change.\n","For a casual introduction to some of the core principles, see\n","[Horace He's blogpost](https://horace.io/brrr_intro.html)."],"metadata":{"id":"LD9GVFCBMQqQ"}},{"cell_type":"markdown","source":["# Adding validation data and organizing data code with a `DataModule`"],"metadata":{"id":"yS6wkFvHMiIC"}},{"cell_type":"markdown","source":["모델이 이미 확인한 데이터(training set)을 맞추는 것은 인상적이지 않다.     \n","모델 학습에 사용되지 않은 데이터(validation set)에 대해서 성능을 확인해본다."],"metadata":{"id":"lxzHRsMVNo6L"}},{"cell_type":"markdown","source":["일반적으로 데이터 로드 코드는 복잡하고, 동기화가 되기 힘들게 짜질 수 있다.     \n","적절한 `DataModule`코드를 작성하면 유용하게 쓰일 수 있다."],"metadata":{"id":"ALa3CyMPPqip"}},{"cell_type":"code","source":["class MNISTDataModule:\n","    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n","    filename = \"mnist.pkl.gz\"\n","\n","    def __init__(self, dir, bs=32):\n","        self.dir = dir\n","        self.bs = bs\n","        self.path = self.dir / self.filename\n","\n","    def prepare_data(self):\n","        if not (self.path).exists():\n","            content = requests.get(self.url + self.filename).content\n","            self.path.open('wb').write(content)\n","    \n","    def setup(self):\n","        with gzip.open(self.path, 'rb') as f:\n","            ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n","        \n","        x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))\n","\n","        self.train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n","        self.valid_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(self.train_ds, batch_size=self.bs, shuffle=True)\n","    \n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(self.valid_ds, batch_size=self.bs, shuffle=False) # valid는 shuffle False"],"metadata":{"id":"9GVGj1E4Rm5v","executionInfo":{"status":"ok","timestamp":1660195654936,"user_tz":-540,"elapsed":2,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["`DataModule`에 대해서는 나중에 자세히 살펴본다.    \n","이제 `DataModule`을 fitting pipeline에 추가한다.\n"],"metadata":{"id":"aeKER2yXX0mY"}},{"cell_type":"code","source":["def fit(self: nn.Module, datamodule):\n","    datamodule.prepare_data()\n","    datamodule.setup()\n","\n","    val_dataloader = datamodule.val_dataloader()\n","\n","    self.eval()\n","    with torch.no_grad():\n","        valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n","\n","    print(\"before start of training:\", valid_loss / len(val_dataloader))\n","\n","    opt = configure_optimizer(self)\n","    train_dataloader = datamodule.train_dataloader()\n","    for epoch in range(epochs):\n","        self.train()\n","        for xb, yb in train_dataloader:\n","            pred = self(xb)\n","            loss = loss_func(pred, yb)\n","\n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","\n","        self.eval()\n","        with torch.no_grad():\n","            valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n","        \n","        print(epoch, valid_loss / len(val_dataloader))\n","    \n","MNISTLogistic.fit = fit\n","MLP.fit = fit"],"metadata":{"id":"8PDNJfMtZB1q","executionInfo":{"status":"ok","timestamp":1660196868534,"user_tz":-540,"elapsed":433,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["model = MLP(data_config)\n","model.to(device)\n","\n","datamodule = MNISTDataModule(dir=path, bs=32)\n","\n","model.fit(datamodule=datamodule)"],"metadata":{"id":"YWk2RPDtbYsX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660196929067,"user_tz":-540,"elapsed":60535,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"ed4091e8-f52a-4323-f112-023848b10fed"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["before start of training: tensor(2.3026)\n","0 tensor(0.1813)\n","1 tensor(0.1101)\n"]}]},{"cell_type":"markdown","source":["이제 아래의 코드만드로 학습이 가능하다."],"metadata":{"id":"wWaqyQEHcGTN"}},{"cell_type":"code","source":["model = MLP(data_config)\n","model.to(device)\n","\n","datamodule = MNISTDataModule(dir=path, bs=32)\n","\n","model.fit(datamodule=datamodule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLmeQCL8c0L-","executionInfo":{"status":"ok","timestamp":1660197028777,"user_tz":-540,"elapsed":60469,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"aa317088-03b7-41b8-e098-2643e24bee96"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["before start of training: tensor(2.3054)\n","0 tensor(0.1719)\n","1 tensor(0.1072)\n"]}]},{"cell_type":"markdown","source":["`.fit` 매서드에서 주의깊게 봐야할 점은 아래와 같다.     \n","- `self.eval` vs `self.train`: [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n","and\n","[BatchNorm](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) 과 같이 훈련과 검증 시 다르게 동작하는 레이어들의 training과 evaliadation 단계의 동작을 손쉽게 바꿔준다.      \n","- `torch.no_grad` 를 사용하면 tensor계산시에 parameter들을 학습시키 위해 사용되는 gradient를 구하기 위한 tracking을 적용하지 않는다.       \n","검증시와 같이 모델 훈련에 사용되지 않는 과정의 경우 필요하다."],"metadata":{"id":"upKyoRWPc1Rb"}},{"cell_type":"markdown","source":["# Excercise"],"metadata":{"id":"_KQXA1-vdBye"}},{"cell_type":"markdown","source":["## Try out different hyperparameters for the `MLP` and for training"],"metadata":{"id":"Mku9bSqIeI1w"}},{"cell_type":"markdown","source":["mlp를 보면 dropout 옵션을 설정할 수 있는 것을 알 수 있다."],"metadata":{"id":"mEwK-61cebOc"}},{"cell_type":"code","source":["MLP.__init__??"],"metadata":{"id":"5H2jCKbCeQWv","executionInfo":{"status":"ok","timestamp":1660201748345,"user_tz":-540,"elapsed":345,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":["As the type signature indicates, `args` is an `argparse.Namespace`.\n","[`argparse` is used to build command line interfaces in Python](https://realpython.com/command-line-interfaces-python-argparse/),\n","and later on we'll see how to configure models\n","and launch training jobs from the command line\n","in the FSDL codebase.\n","\n","For now, we'll do it by hand, by passing a dictionary to `Namespace`.\n","\n","Edit the cell below to change the `args`, `epochs`, and `b`atch `s`ize.\n","\n","Can you get a final `valid`ation `acc`uracy of 98%?\n","Can you get to 95% 2x faster than the baseline `MLP`?"],"metadata":{"id":"kZEomFOzeUxJ"}},{"cell_type":"code","source":["import argparse\n","from argparse import Namespace\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--fc_dropout')\n","\n","args = parser.parse_args(['--fc_dropout=0.2'])\n","print(args.fc_dropout)\n","args = vars(args) if parser is not None else {}\n","# \n","print(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhxXGWdqjMm3","executionInfo":{"status":"ok","timestamp":1660199559792,"user_tz":-540,"elapsed":3,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"975740cc-5baf-4b7d-db2e-8156679f8b30"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["0.2\n","{'fc_dropout': '0.2'}\n"]}]},{"cell_type":"code","source":["model = MLP(data_config, args=args)"],"metadata":{"id":"UuYIqph7vGDA","executionInfo":{"status":"ok","timestamp":1660201757053,"user_tz":-540,"elapsed":335,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["model.__dict__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsD3AMTVvHHk","executionInfo":{"status":"ok","timestamp":1660201766365,"user_tz":-540,"elapsed":342,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"44b596f4-ab3f-42a2-9854-3c87e808c8ec"},"execution_count":140,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'_backward_hooks': OrderedDict(),\n"," '_buffers': OrderedDict(),\n"," '_forward_hooks': OrderedDict(),\n"," '_forward_pre_hooks': OrderedDict(),\n"," '_is_full_backward_hook': None,\n"," '_load_state_dict_post_hooks': OrderedDict(),\n"," '_load_state_dict_pre_hooks': OrderedDict(),\n"," '_modules': OrderedDict([('fc1',\n","               Linear(in_features=784, out_features=1024, bias=True)),\n","              ('dropout', Dropout(p=0.2, inplace=False)),\n","              ('fc2', Linear(in_features=1024, out_features=128, bias=True)),\n","              ('fc3', Linear(in_features=128, out_features=10, bias=True))]),\n"," '_non_persistent_buffers_set': set(),\n"," '_parameters': OrderedDict(),\n"," '_state_dict_hooks': OrderedDict(),\n"," 'args': {'fc_dropout': 0.2},\n"," 'data_config': {'input_dims': (784,),\n","  'mapping': {0: '0',\n","   1: '1',\n","   2: '2',\n","   3: '3',\n","   4: '4',\n","   5: '5',\n","   6: '6',\n","   7: '7',\n","   8: '8',\n","   9: '9'}},\n"," 'training': True}"]},"metadata":{},"execution_count":140}]},{"cell_type":"code","source":["%%time\n","import argparse\n","from argparse import Namespace\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--fc_dropout', action='store', type=float)\n","args = parser.parse_args(['--fc_dropout', '0.2'])\n","print(args.fc_dropout)\n","epochs = 2\n","bs = 32\n","\n","\n","def configure_optimzier(model: nn.Module) -> optim.Optimizer:\n","    return optim.Adam(model.parameters(), le=3e-4)\n","\n","\n","model = MLP(data_config, args=args)\n","model.to(device)\n","\n","datamodule = MNISTDataModule(dir=path, bs=bs)\n","\n","model.fit(datamodule=datamodule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdmXgOhUela5","executionInfo":{"status":"ok","timestamp":1660199671303,"user_tz":-540,"elapsed":65293,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"98f7ba4a-eb4b-4427-c803-566a5d8014a0"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["0.2\n","before start of training: tensor(2.2991)\n","0 tensor(0.1426)\n","1 tensor(0.0852)\n","CPU times: user 58.5 s, sys: 3.71 s, total: 1min 2s\n","Wall time: 1min 5s\n"]}]},{"cell_type":"code","source":["val_dataloader = datamodule.val_dataloader()\n","valid_acc = sum(accuracy(model(xb), yb) for xb, yb in val_dataloader) / len(val_dataloader)\n","valid_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2AdZlTDf0g2","executionInfo":{"status":"ok","timestamp":1660199080618,"user_tz":-540,"elapsed":4268,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"8f2a8f8f-144b-4941-8bdb-e188d02efd43"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9675)"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","source":["# Write your own `nn.Module`"],"metadata":{"id":"XfcAWBLkgYXu"}},{"cell_type":"markdown","source":["Designing new models is one of the most fun\n","aspects of building an ML-powered application.\n","\n","Can you make an `nn.Module` that looks different from\n","the standard `MLP` but still gets 98% validation accuracy or higher?\n","You might start from the `MLP` and\n","[add more layers to it](https://i.imgur.com/qtlP5LI.png)\n","while adding more bells and whistles.\n","Take care to keep the shapes of the `Tensor`s aligned as you go.\n","\n","Here's some tricks you can try that are especially helpful with deeper networks:\n","- Add [`BatchNorm`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)\n","layers, which can improve\n","[training stability and loss conditioning](https://myrtle.ai/how-to-train-your-resnet-7-batch-norm/)\n","- Add a linear \"skip connection\" layer that is applied to the inputs and whose outputs are added directly to the last layer's outputs\n","- Use other [activation functions](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions),\n","like [selu](https://pytorch.org/docs/stable/generated/torch.nn.functional.selu.html)\n","or [mish](https://pytorch.org/docs/stable/generated/torch.nn.functional.mish.html)\n","\n","If you want to make an `nn.Module` that can have different depths,\n","check out the\n","[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) class."],"metadata":{"id":"MWoab2g_ggaO"}},{"cell_type":"code","source":["torch.zeros(3, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCaQoTYTuQ6Q","executionInfo":{"status":"ok","timestamp":1660201545743,"user_tz":-540,"elapsed":2,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"f48e88b0-f500-4b36-ea6d-f935066441ed"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0.],\n","        [0., 0.],\n","        [0., 0.]])"]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["import numpy as np\n","from typing import Dict, Any\n","\n","FC1_DIM = 1024\n","FC2_DIM = 1024\n","FC_DROPOUT=0.2\n","\n","class YourModel(nn.Module):\n","    \n","    def __init__(self, data_config: Dict[str, Any], args: argparse.Namespace = None) -> None:\n","        super().__init__()\n","        self.args = vars(args) if args is not None else {}\n","        self.data_config = data_config\n","\n","        input_dim = np.prod(self.data_config[\"input_dims\"])\n","        num_classes = len(self.data_config[\"mapping\"])\n","\n","        fc1_dim = self.args.get(\"fc1\", FC1_DIM)\n","        fc2_dim = self.args.get(\"fc2\", FC2_DIM)\n","        dropout_p = self.args.get(\"fc_dropout\", FC_DROPOUT)\n","\n","        self.ps = nn.Parameter(torch.zeros(input_dim, 10))\n","        self.fc1 = nn.Linear(input_dim, fc1_dim)\n","        self.act1 = nn.ReLU()\n","        self.batch_norm1 = nn.BatchNorm1d(fc1_dim)\n","        self.dropout1 = nn.Dropout(dropout_p)\n","        \n","        self.fc2 = nn.Linear(fc1_dim, fc2_dim)\n","        self.act2 = nn.ReLU()\n","        self.batch_norm2 = nn.BatchNorm1d(fc2_dim)\n","        self.dropout2 = nn.Dropout(dropout_p)\n","        \n","        self.fc3 = nn.Linear(fc2_dim, num_classes)\n","\n","    def forward(self, xb):\n","        x_skip = xb @ self.ps\n","        xb = self.dropout1(self.act1(self.batch_norm1(self.fc1(xb))))\n","        xb = self.dropout2(self.act2(self.batch_norm2(self.fc2(xb))))\n","        xb = self.fc3(xb)\n","\n","        return xb + x_skip\n","\n","YourModel.fit = fit  # don't forget this!"],"metadata":{"id":"8TpKRZV7nCbT","executionInfo":{"status":"ok","timestamp":1660201794969,"user_tz":-540,"elapsed":407,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["model = YourModel(data_config)\n","model.to(device)\n","\n","datamodule = MNISTDataModule(dir=path, bs=bs)\n","\n","model.fit(datamodule=datamodule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hj-Hofzvsxtb","executionInfo":{"status":"ok","timestamp":1660201902154,"user_tz":-540,"elapsed":107187,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"fc0faaaf-2b79-403b-b74d-896256fdd7b1"},"execution_count":144,"outputs":[{"output_type":"stream","name":"stdout","text":["before start of training: tensor(2.3082)\n","0 tensor(0.0766)\n","1 tensor(0.0445)\n"]}]},{"cell_type":"code","source":["val_dataloader = datamodule.val_dataloader()\n","valid_acc = sum(accuracy(model(xb), yb) for xb, yb in val_dataloader) / len(val_dataloader)\n","valid_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O92llyBns3C0","executionInfo":{"status":"ok","timestamp":1660201907987,"user_tz":-540,"elapsed":5843,"user":{"displayName":"HyeonGeun Yoon","userId":"03668824595815287272"}},"outputId":"9404546f-4d69-4b87-b3bc-614130e1784f"},"execution_count":145,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9871)"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":[""],"metadata":{"id":"onCnEf0iu4pL"},"execution_count":null,"outputs":[]}]}